#create polygon from grid edges
edges <-distinct(rbind(edge3[,3:4],edge4[,3:4]))
testpoly <- Polygon(edges)
testpoly <- Polygons(list(testpoly),1)
testpoly <- SpatialPolygons(list(testpoly))
spoly <-gSimplify(testpoly, tol=0.0001)
#intersect grid outline and voronoi polygons
gridxy <- gridcsv[,3:4]
vorgrid <- voronoi(gridxy)
gridcut <- gIntersection(spoly,gridcut,byid=FALSE,drop_lower_td = FALSE)
intersect(vorgid,gridxy)
intersect(vorgrid,gridxy)
View(gridcsv)
View(gridxy)
raster::intersect(vorgrid,gridxy)
extent(gridxy)
extent(vor_grid)
extent(grid_xy)
extent(spoly)
raster::intersect(vorgrid,gridcut)
gridcut <- gIntersection(vorgrid,spoly,byid=FALSE,drop_lower_td=FALSE)
plot(gridcut)
#intersect
test1<-intersect(vorgrid,spoly)
plot(test1)
class(grid_xy)
View(gridcsv)
p <- matrix(c(17, 42, 85, 70, 19, 53, 26, 84, 84, 46, 48, 85, 4, 95, 48, 54, 66, 74, 50, 48,
28, 73, 38, 56, 43, 29, 63, 22, 46, 45, 7, 60, 46, 34, 14, 51, 70, 31, 39, 26), ncol=2)
v <- voronoi(p)
v
gridxy <- gridcsv[,2:4]
test2<-SpatialPointsDataFrame(gridxy[,2:3],data=gridxy[,1])
vortest <-voronoi(test2)
ssplot(vortest, col.regions=gray(seq(0,10,310)))
spplot(vortest, col.regions=gray(seq(0,10,310)))
spplot(vortest, col.regions=blue(seq(0,310,62)))
spplot(vortest, col.regions=gray(seq(0,310,62)))
spplot(vortest, col.regions=gray(seq(0,1,62)))
#import iRIC calculation grid .csv
iricOutPath <- "U:\\iRIC tutorials\\outputs\\"
gridcsv <-fread(paste(iricOutPath,"calcgrid",".csv",sep = ""), header=TRUE, sep=",",skip=2,drop=c("K","Z"))
#get points on edges of grid
edge3<-gridcsv %>% filter(J == 0)
edge4<-gridcsv %>% filter(J == max(gridcsv[,2]))
#flip the order of the data frame
edge4<-edge4[dim(edge4)[1]:1,]
#create polygon from grid edges
edges <-distinct(rbind(edge3[,3:4],edge4[,3:4]))
testpoly <- Polygon(edges)
testpoly <- Polygons(list(testpoly),1)
testpoly <- SpatialPolygons(list(testpoly))
spoly <-gSimplify(testpoly, tol=0.0001)
#intersect grid outline and voronoi polygons
gridxy <- gridcsv[,2:4]
vorgrid <- voronoi(gridxy)
gridcut <- intersect(vorgrid,spoly)
#create polygon from grid edges
edges <-distinct(rbind(edge3[,3:4],edge4[,3:4]))
testpoly <- Polygon(edges)
testpoly <- Polygons(list(testpoly),1)
testpoly <- SpatialPolygons(list(testpoly))
spoly <-gSimplify(testpoly, tol=0.0001)
#intersect grid outline and voronoi polygons
gridxy <- gridcsv[,3:4]
vorgrid <- voronoi(gridxy)
gridcut <- intersect(vorgrid,spoly
)
plot(gridcut)
#import .tpo data
iricOutPath <- "U:\\iRIC tutorials\\outputs\\chris_results1_"
tpoOut <-fread(paste(iricOutPath,"Elevation",".tpo",sep = ""), header=FALSE, sep=",")
#create raster from .tpo
tpoSpdf <- SpatialPointsDataFrame(tpoOut[,c(1,2)],tpoOut[,3])
rastHold <- raster()
extent(rastHold)<-extent(tpoSpdf)
#iRIC sample data missing CRS info
crs(rastHold)<-proj4string(tpoSpdf)
##interpolate raster to fill holes: nearest neighbor
gs<-gstat(formula=tpoSpdf$V3~1,data=tpoSpdf)
idwOut<-interpolate(rastHold,gs)
plot(idwOut)
rastXYZ <- rasterize(tpoSpdf,rastHold,tpoSpdf$V3)
plot(rastXYZ)
gridxy <- SpatialPointsDataFrame(gridcsv[,3:4],gridcsv[,2])
vorgrid <- voronoi(gridxy)
gridcut <- intersect(vorgrid,gridBound)
gridBound <-gSimplify(epoly, tol=0.0001)
edges <-distinct(rbind(edge3[,3:4],edge4[,3:4]))
epoly <- Polygon(edges)
epoly <- Polygons(list(epoly),1)
epoly <- SpatialPolygons(list(epoly))
gridBound <-gSimplify(epoly, tol=0.0001)
gridcut <- intersect(vorgrid,gridBound)
plot(gridcut)
plot(gridxy)
spplot(gridcut,J,colorkey=TRUE)
spplot(gridcut,gricut$J,colorkey=TRUE)
spplot(gridcut,gridcut$J,colorkey=TRUE)
spplot(gridcut,gridcut[,1],colorkey=TRUE)
spplot(gridcut,zcol=gridcut[,1],colorkey=TRUE)
spplot(gridcut,colorkey=TRUE)
plot(tpoSpdf)
head(tpoOut)
plot(epoly)
plot(gridBound)
#import .tpo data
iricOutPath <- "U:\\iRIC tutorials\\outputs\\"
tpoOut <-fread(paste(iricOutPath,"chris_results1_Elevation",".tpo",sep = ""), header=FALSE, sep=",")
#create raster from .tpo
tpoSpdf <- SpatialPointsDataFrame(tpoOut[,c(1,2)],tpoOut[,3])
rastHold <- raster()
extent(rastHold)<-extent(tpoSpdf)
#iRIC sample data missing CRS info
crs(rastHold)<-proj4string(tpoSpdf)
#intersect grid outline and voronoi polygons
get.grid(iricOutPath)
vorgrid <- voronoi(tpoSpdf)
gridcut <- intersect(vorgrid,gridBound)
spplot(gridcut,colorkey=TRUE)
source("get.grid.R")
get.grid(iricOutPath)
do.call(get.grid, iricOutPath)
call(get.grid)
#begin function
get.grid <- function(iricOutPath){
gridcsv <-fread(paste(iricOutPath,"calcgrid",".csv",sep = ""), header=TRUE, sep=",",skip=2,drop=c("K","Z"))
#get points on edges of grid
edge3<-gridcsv %>% filter(J == 0)
edge4<-gridcsv %>% filter(J == max(gridcsv[,2]))
#flip the order of the data frame
edge4<-edge4[dim(edge4)[1]:1,]
#create polygon from grid edges
edges <-distinct(rbind(edge3[,3:4],edge4[,3:4]))
epoly <- Polygon(edges)
epoly <- Polygons(list(epoly),1)
gridBound <- SpatialPolygons(list(epoly))
return(gridBound)
}
get.grid(iricOutPath)
vorgrid <- voronoi(tpoSpdf)
gridcut <- intersect(vorgrid,gridBound)
spplot(gridcut,colorkey=TRUE)
library("deldir", lib.loc="U:/R/win-library/3.4")
library("dismo", lib.loc="U:/R/win-library/3.4")
vorgrid <- voronoi(tpoSpdf)
gridcsv <-fread(paste(iricOutPath,"calcgrid",".csv",sep = ""), header=TRUE, sep=",",skip=2,drop=c("K","Z"))
#import iRIC calculation grid .csv
iricOutPath <- "U:\\iRIC tutorials\\outputs\\"
gridcsv <-fread(paste(iricOutPath,"calcgrid",".csv",sep = ""), header=TRUE, sep=",",skip=2,drop=c("K","Z"))
#get points on edges of grid
edge3<-gridcsv %>% filter(J == 0)
edge4<-gridcsv %>% filter(J == max(gridcsv[,2]))
#flip the order of the data frame
edge4<-edge4[dim(edge4)[1]:1,]
#create polygon from grid edges
edges <-distinct(rbind(edge3[,3:4],edge4[,3:4]))
epoly <- Polygon(edges)
epoly <- Polygons(list(epoly),1)
gridBound <- SpatialPolygons(list(epoly))
return(gridBound)
#begin function
get.grid <- function(iricOutPath){
gridcsv <-fread(paste(iricOutPath,"calcgrid",".csv",sep = ""), header=TRUE, sep=",",skip=2,drop=c("K","Z"))
#get points on edges of grid
edge3<-gridcsv %>% filter(J == 0)
edge4<-gridcsv %>% filter(J == max(gridcsv[,2]))
#flip the order of the data frame
edge4<-edge4[dim(edge4)[1]:1,]
#create polygon from grid edges
edges <-distinct(rbind(edge3[,3:4],edge4[,3:4]))
epoly <- Polygon(edges)
epoly <- Polygons(list(epoly),1)
gridBound <- SpatialPolygons(list(epoly))
return(gridBound)
} #end get.grid function
#intersect grid outline and voronoi polygons
gridxy <- SpatialPointsDataFrame(gridcsv[,3:4],gridcsv[,2])
vorgrid <- voronoi(gridxy)
tpoOut <-fread(paste(iricOutPath,"chris_results1_Elevation",".tpo",sep = ""), header=FALSE, sep=",")
tpoSpdf <- SpatialPointsDataFrame(tpoOut[,c(1,2)],tpoOut[,3])
class(gridcsv)
class(tpoSpdf)
tpoSpdf <- SpatialPointsDataFrame(tpoOut[,1:3])
#create raster from .tpo
tpoSpdf <- SpatialPointsDataFrame(tpoOut[,1:2],tpoOut[,3])
vorgrid <- voronoi(tpoSpdf)
tpoSpdf[,1:2]
tpoSpdf$V3
gridxy[,3]
gridxy$J
voronoi(tpoSpdf)
deldir(tpoSpdf)
deldir(gridxy)
View(tpoOut)
View(gridcsv)
names(tpoSpdf) <-c("X","Y","Z")
View(gridcsv)
View(tpoOut)
names(tpoOut) <-c("X","Y","Z")
View(tpoOut)
tpoSpdf <- SpatialPointsDataFrame(tpoOut[,1:2],tpoOut[,3])
vorgrid <- voronoi(tpoSpdf)
.libpaths()
.libPaths()
myPaths <- .libPaths()   # get the paths
myPaths <- c(myPaths[2], myPaths[1])  # switch them
.libPaths(myPaths)  # reassign them
# Load required packages
packages <- c("SDMTools","sp","raster","rgeos","rgdal","sf","spatstat","spdep","tidyverse","rasterVis","ggplot2","data.table","dpylr","plotly")
#  Check to see if each is installed, and install if not.
if (length(setdiff(packages, rownames(installed.packages()))) > 0) {
install.packages(setdiff(packages, rownames(installed.packages())))
}
library
help("Startup")
.libPaths()
.libPaths()
install.packages("dataRetrieval")
install.packages("FlowScreen")
install.packages("hydroTSM")
# Function: This script serves as the master script that controls which functions are run and what inputs are used for finding suitable fish habitat
#         It will later be converted to the script that controls the Shiny App.
# Last edited by Elaina Passero on 06/03/19
# Load required packages
packages <- c("SDMTools","sp","raster","rgeos","rgdal","sf","spatstat","spdep","tidyverse","rasterVis",
"ggplot2","data.table","dplyr","plotly","spex","stars","igraph","deldir","hydroTSM")
#  Check to see if each is installed, and install if not.
if (length(setdiff(packages, rownames(installed.packages()))) > 0) {
install.packages(setdiff(packages, rownames(installed.packages())))
}
# load the installed libraries in the packages list
lapply(packages,library,character.only=TRUE)
### Begin Inputs ###
## Primary Inputs
wd <- "C:/Users/epassero/Desktop/VRDSS/verde-refdss/"
#wd <- "/Users/Morrison/Documents/Active Research Projects/Verde REFDSS/verde-refdss/" # Set path to local repository
setwd(wd)
habMets <- list("Depth","Velocity") #Variables from iRIC calculation result used for habitat analysis ex: Velocity..magnitude.
specieslist <- c("longfindace","yellowbullhead","desertsucker","sonoransucker","redshiner","roundtailchub","greensunfish","fatheadminnow","speckleddace")
species <- "longfindace"
lifestages <- list("adult") #lifestages from oldest to youngest; must match order in HSC table
reachName <- "Beasley1" # Should match name of folder with results
disunit <- "cms" #units of discharge
## Secondary Inputs - Use only if switching between projects
Check0Flow <- "No" # Yes- Calculate max area for 0-flow scenario and interpolate below min modeled Q
# Yes- external rasters or No- rasterize iRIC results. Inputs required if No.
LoadExternal <- "No"; if(LoadExternal=="No"){
skipnum <- 2 # number of rows to skip when reading in CSV results
xLoc <- "X" # field name of X coordinate in CSVs
yLoc <- "Y" # field name of y coordinate in CSVs
DEM <- "VerdeBeasley1Elev.tif" # Name of DEM: VerdeBeasley1Elev.tif, smrf_DEM_v241.tif, braidallpts_DEM.tif, GilaMGnd.tif
# Does the resolution of the rasters need to be manually set? If No, DEM resolution will be used.
setRes <- "No"; if(setRes=="Yes"){
res <- c(10,10)} # resolution of rasters if they need to be manually set
if(Check0Flow=="Yes"){
depth0Flow <- "insert depth raster layer"
}# end of internal rasterization inputs;
}
## Options - If set to No, inputs are not required for option
# Yes or No. Choose whether or not to check substrate conditions as part of suitable habitat
CheckSub <- "Yes"; if(CheckSub=="Yes"){
subName <- "BeasleyUS_SedThiessenPoly1Dissolved"}
# Yes or No. Choose whether or not to remove isolated (single cell) habitat patches
RemoveIslands <- "Yes"; if(RemoveIslands=="Yes"){
islandSize <- 2} # number of raster cells that is considered too small of a habitat patch
# Yes or No. Choose whether or not to normalize habitat area by reach length
NormalizeByL <- "No"; if(NormalizeByL=="Yes"){
reachL <- 0.61
unitL <- "km"} # Reach length in km. If not normalizing set equal to 1.
# Yes or No. Will a hydrograph be supplied? If "No" CalcXDayStats and DateRange can be left blank.
FlowScenario <- "Yes"; if(FlowScenario=="Yes"){
# Yes or No. Choose whether or not to calculate X-day statistics. Must supply number of days.
CalcXDayStats <- "No"; if(CalcXDayStats=="Yes"){
xDays <- 7} # number of days for moving discharge and area statistics
# Yes or No. Yes - limit analysis to supplied dates. No - consider entire hydrograph.
DateRange <- "No"; if(DateRange=="Yes"){
startDate <- "1993-10-01" # "YYYY-MM-DD"
endDate <- "1994-03-30"} # "YYYY-MM-DD"
} # End of flow scenario related options
### Begin Processing ###
if(LoadExternal == "No"){
## Format result CSVs and get list of discharges
source("get.results.R")
holdList <- get.results(wd,reachName,skipnum,disunit)
csvList <- holdList$csvList
modeled_q <- holdList$modeled_q
rm(holdList)
### for cherry Creek ###
#source("exp.shp.R")
#resultsPts <- lapply(habMets, function(a) exp.shp(a,csvList,wd,DEM,reachName,xLoc,yLoc))
## Convert iRIC outputs to rasterBricks by variable
source("iric.process.smr.R")
outValRast <- list()
outValRast <- lapply(habMets, function(m) iric.process.smr(m,csvList,wd,DEM,reachName,setRes,xLoc,yLoc))
names(outValRast) <-habMets
rm(csvList)} else{
## Load in external rasterBricks and discharges
source("load.cherry.R")
#reachCode <- "del1"
outValRast <- load.cherry(wd,reachName,reachCode)
names(outValRast)<-c(habMets,"modeled_q")
modeled_q <- outValRast$modeled_q
outValRast[length(outValRast)]<-NULL
}
## Read in hydrograph if one is supplied
if(FlowScenario == "Yes"){
hydrograph <- na.omit(fread(paste(wd,reachName,"_hydrograph",".csv",sep=""),header=TRUE, sep = ",",data.table=FALSE))
hydrograph$date <- as.Date(hydrograph$date, format="%m/%d/%Y")
if(DateRange=="Yes"){
hydrograph <- subset(hydrograph, date > as.Date(startDate))
hydrograph <- subset(hydrograph, date < as.Date(endDate))
}
}
## Load substrate
if(CheckSub == "Yes"){
baseRast <- outValRast[[1]][[1]] # will be overwritten during rasterization - provides setup
subMap <- readOGR(dsn=paste(wd,"results","/",reachName,sep = ""),layer=subName) # read in substrate shapefile
#rastSubMap <- rasterize(subMap,baseRast,field=subMap@data$substrate,update=TRUE)
rastSubMap <- rasterize(subMap,baseRast,field=subMap@data$ParticalSi,update=TRUE)
}
##### Run for all species #####
outputs <- list()
outputs <- lapply(specieslist, function(species){ # builds tables and maps for all species in list
## Reclassify Bricks with hydraulic and substrate HSC by lifestage
source("find.hsc.R"); source("bricks.rc.R"); source("by.substrate.R"); source("find.sub.R"); source("remove.islands.R")
hsc_allspec<-fread(paste(wd,reachName,"_hsc",".csv",sep = ""), header=TRUE, sep=",",data.table = FALSE)
hsc_allages <- find.hsc(hsc_allspec,species) # extract HSC for single species
goodHabList <- lapply(lifestages, function(a) bricks.rc(a,outValRast,hsc_allages,habMets))
names(goodHabList) <- lifestages # list of Bricks by lifestage
# Not sure if this is working correctly yet
if(CheckSub == "Yes"){
sub_allspec <- fread(paste(wd,reachName,"_substrate",".csv",sep=""),header=TRUE, sep = ",",data.table = FALSE) # load substrate requirements
sub_allages <- find.sub(sub_allspec,species) # extract substrate requirements for single species
goodHabList <- lapply(lifestages, function(a) by.substrate(a, goodHabList, sub_allages,rastSubMap))
names(goodHabList) <- lifestages
} # end of if statement
if(RemoveIslands == "Yes"){
goodHabList <- lapply(lifestages, function(a) remove.islands(a,goodHabList,RemoveIslands,islandSize))
names(goodHabList) <- lifestages
}
## Total available habitat area by lifestage
source("total.area.R")
areaLookTab <- lapply(lifestages, function(a) total.area(a,goodHabList,modeled_q,NormalizeByL,reachL,habMets))
names(areaLookTab) <- lifestages
## Order rasters of total available habitat by modeled discharge
source("rast.by.q.R")
rastByQ <- lapply(lifestages, function(a) rast.by.q(a,goodHabList,modeled_q))
names(rastByQ) <- lifestages
## Generate Interpolated Discharge-Area Lookup Tables from Hydrograph and Regression if hydrograph provided
if(FlowScenario=="Yes"){
source("interp.table.R")
interTab <- lapply(lifestages, function(a) interp.table(a,hydrograph,areaLookTab,NormalizeByL))
names(interTab) <- lifestages
## Generate and view plots of total area through the hydrograph
#source("interp.plot.R")
#interPlots <- lapply(lifestages, function(a) interp.plot(a,interTab,NormalizeByL))
#head(interPlots)
## Generate Data Frames of moving X-Day area and discharge statistics
if(CalcXDayStats=="Yes"){
source("x.day.stats.R")
xDayStats <- lapply(lifestages, function(a) x.day.stats(a,interTab,xDays))
names(xDayStats) <- lifestages
}
source("avg.month.area.R")
avgMonthlyArea <- lapply(lifestages, function(a) avg.month.area(a,interTab,NormalizeByL))
names(avgMonthlyArea) <- lifestages
# end of flow scenario dependent processes
# condense outputs into single list
outputs$areaLookTab <- areaLookTab
outputs$rastByQ <- rastByQ
outputs$avgMonthlyArea <- avgMonthlyArea
} else{ # outputs not including any flow-scenario related outputs
# condense outputs into a single list
outputs$areaLookTab <- areaLookTab
outputs$rastByQ <- rastByQ
}
return(outputs)
}) # end of species list function
names(outputs) <- specieslist
# Put tables in a nice format
tables <- lapply(specieslist, function(species){
outputs[[species]]$areaLookTab
})
names(tables) <- specieslist
## Generate plots of length-normalized area by discharge for all species
plottable <- data.frame(tables[[1]]$adult$discharge)
for(i in 1:length(tables)){
#plottable[,i+1] <- tables[[i]]$adult$normalizedArea
plottable[,i+1] <- tables[[i]]$adult$totalArea
}
colnames(plottable) <- c("discharge",specieslist)
plot_ly(plottable,x=~discharge) %>%
add_lines(y=plottable[,2],name=names(plottable[2]),line=list(color='black')) %>%
add_lines(y=plottable[,3],name=names(plottable[3]),line=list(color='orange')) %>%
add_lines(y=plottable[,4],name=names(plottable[4]),line=list(color='teal')) %>%
add_lines(y=plottable[,5],name=names(plottable[5]),line=list(color='blue')) %>%
add_lines(y=plottable[,6],name=names(plottable[6]),line=list(color='red')) %>%
add_lines(y=plottable[,7],name=names(plottable[7]),line=list(color='yellow')) %>%
add_lines(y=plottable[,8],name=names(plottable[8]),line=list(color='green')) %>%
add_lines(y=plottable[,9],name=names(plottable[9]),line=list(color='purple')) %>%
add_lines(y=plottable[,10],name=names(plottable[10]),line=list(color='pink')) %>%
layout(title="Habitat-discharge for Braided site w/ Substrate w/o LWD",xaxis=list(title="Discharge (cfs)"),yaxis=list(title="Total Area m2"))
#writeRaster(outputs$greensunfish$rastByQ$adult,"gsf250.tif",format="GTiff")
# read in historical flow record
hydrograph <- na.omit(fread(paste(wd,reachName,"_hydrograph",".csv",sep=""),header=TRUE, sep = ",",data.table=FALSE))
hydrograph$date <- as.Date(hydrograph$date, format="%m/%d/%Y")
# calculate exceedence probability
hydroEP <- data.frame(discharge = hydrograph$discharge,rank=rank(hydrograph$discharge,ties.method = "min")) # ranks discharges; same values get same ranks
n <- as.numeric(length(hydroEP$discharge))
hydroEP$EP <- hydroEP$rank/(1+n)
# add in modeled discharges and interpolate to get EP's
dfMQ <- data.frame(discharge=modeled_q)
uniqueQ <- bind_rows(hydroEP,data.frame(anti_join(dfMQ["discharge"],hydroEP["discharge"]))) # all discharges that will be in area-lookup table
uniqueQ <- unique(arrange(uniqueQ,discharge)) # puts discharges in ascending order and removes duplicates
intTot <- approx(uniqueQ,method="linear",xout=uniqueQ$discharge) # linearly interpolate for missing total available area values
View(intTot)
intTot <- data.frame(approx(uniqueQ,method="linear",xout=uniqueQ$discharge)) # linearly interpolate for missing total available area values
View(intTot)
View(uniqueQ)
intTot <- data.frame(approx(x=uniqueQ$discharge,y=uniqueQ$EP,method="linear",xout=uniqueQ$discharge)) # linearly interpolate for missing total available area values
View(intTot)
plot(intTot)
plot(x=intTot$y,y=intTot$x)
View(hydroEP)
# calculate exceedence probability
hydroEP <- data.frame(discharge = hydrograph$discharge,rank=rank(-hydrograph$discharge,ties.method = "min")) # ranks discharges; same values get same ranks
n <- as.numeric(length(hydroEP$discharge))
hydroEP$EP <- hydroEP$rank/(1+n)
# add in modeled discharges and interpolate to get EP's
dfMQ <- data.frame(discharge=modeled_q)
uniqueQ <- bind_rows(hydroEP,data.frame(anti_join(dfMQ["discharge"],hydroEP["discharge"]))) # all discharges that will be in area-lookup table
uniqueQ <- unique(arrange(uniqueQ,discharge)) # puts discharges in ascending order and removes duplicates
intTot <- data.frame(approx(x=uniqueQ$discharge,y=uniqueQ$EP,method="linear",xout=uniqueQ$discharge)) # linearly interpolate for missing total available area values
# Reference dagwood sandwich of inundating Q with EP
View(hydroEP)
intTot <- data.frame(approx(discharge=uniqueQ$discharge,EP=uniqueQ$EP,method="linear",xout=uniqueQ$discharge)) # linearly interpolate for missing total available area values
uniqueQ <- unique(arrange(uniqueQ,discharge)) # puts discharges in ascending order and removes duplicates
intTot <- data.frame(approx(x=uniqueQ$discharge,y=uniqueQ$EP,method="linear",xout=uniqueQ$discharge)) # linearly interpolate for missing total available area values
names(intTot) <- c("discharge","EP")
View(intTot)
plot_ly(intTot,x=~EP,y=~discharge)
# read in historical flow record
hydrograph <- na.omit(fread(paste(wd,reachName,"_hydrograph",".csv",sep=""),header=TRUE, sep = ",",data.table=FALSE))
hydrograph$date <- as.Date(hydrograph$date, format="%m/%d/%Y")
# calculate exceedence probability
hydroEP <- data.frame(discharge = hydrograph$discharge,rank=rank(-hydrograph$discharge,ties.method = "min")) # ranks discharges; same values get same ranks
n <- as.numeric(length(hydroEP$discharge))
hydroEP$EP <- hydroEP$rank/(1+n)
# add in modeled discharges and interpolate to get EP's
dfMQ <- data.frame(discharge=modeled_q)
uniqueQ <- bind_rows(hydroEP,data.frame(anti_join(dfMQ["discharge"],hydroEP["discharge"]))) # all discharges that will be in area-lookup table
uniqueQ <- unique(arrange(uniqueQ,discharge)) # puts discharges in ascending order and removes duplicates
intTot <- data.frame(approx(x=uniqueQ$discharge,y=uniqueQ$EP,method="linear",xout=uniqueQ$discharge)) # linearly interpolate for missing total available area values
names(intTot) <- c("discharge","EP")
# Reference dagwood sandwich of inundating Q with EP
# plot FDC to identify the best functions for the tails of the curve
plot_ly(intTot,x=~EP,y=~discharge)
SSasymp(intTot)
SSasymp(intTot,0,0)
exp(intTot)
exp(-intTot)
ugh <- exp(-intTot)
plot(ugh)
ugh <- exp(intTot)
plot(ugh)
ugh <- expm1(intTot)
View(ugh)
install.packages("remotes")
remotes::install_github("mccreigh/rwrfhydro")
install.packages(c("backports", "boot", "callr", "classInt", "clipr", "cluster", "coda", "cowplot", "curl", "dataRetrieval", "dbplyr", "deldir", "devtools", "digest", "dplyr", "e1071", "ellipsis", "evaluate", "foreach", "forecast", "foreign", "fs", "geometry", "ggplot2", "ggpubr", "git2r", "gstat", "haven", "hexbin", "hms", "httr", "igraph", "iterators", "knitr", "labdsv", "lmtest", "lpSolve", "markdown", "MASS", "Matrix", "mgcv", "mime", "nlme", "openssl", "pbapply", "pillar", "pkgbuild", "plotly", "processx", "progress", "quadprog", "quantmod", "R.utils", "raster", "rasterVis", "Rcpp", "RcppArmadillo", "reprex", "reproj", "ResourceSelection", "rgdal", "rgeos", "rlang", "rmarkdown", "rpart", "rvest", "SDMTools", "sf", "shiny", "spatstat", "spex", "stars", "survival", "sys", "tibble", "tinytex", "tseries", "units", "usethis", "vctrs", "xfun", "XML", "xml2", "xtable", "zoo"))
install.packages(c("backports", "boot", "callr", "classInt", "clipr", "cluster", "coda", "cowplot", "curl", "dataRetrieval", "dbplyr", "deldir", "devtools", "digest", "dplyr", "e1071", "ellipsis", "evaluate", "foreach", "forecast", "foreign", "fs", "geometry", "ggplot2", "ggpubr", "git2r", "gstat", "haven", "hexbin", "hms", "httr", "igraph", "iterators", "knitr", "labdsv", "lmtest", "lpSolve", "markdown", "MASS", "Matrix", "mgcv", "mime", "nlme", "openssl", "pbapply", "pillar", "pkgbuild", "plotly", "processx", "progress", "quadprog", "quantmod", "R.utils", "raster", "rasterVis", "Rcpp", "RcppArmadillo", "reprex", "reproj", "ResourceSelection", "rgdal", "rgeos", "rlang", "rmarkdown", "rpart", "rvest", "SDMTools", "sf", "shiny", "spatstat", "spex", "stars", "survival", "sys", "tibble", "tinytex", "tseries", "units", "usethis", "vctrs", "xfun", "XML", "xml2", "xtable", "zoo"))
install.packages(c("backports", "boot", "callr", "classInt", "clipr", "cluster", "coda", "cowplot", "curl", "dataRetrieval", "dbplyr", "deldir", "devtools", "digest", "dplyr", "e1071", "ellipsis", "evaluate", "foreach", "forecast", "foreign", "fs", "geometry", "ggplot2", "ggpubr", "git2r", "gstat", "haven", "hexbin", "hms", "httr", "igraph", "iterators", "knitr", "labdsv", "lmtest", "lpSolve", "markdown", "MASS", "Matrix", "mgcv", "mime", "nlme", "openssl", "pbapply", "pillar", "pkgbuild", "plotly", "processx", "progress", "quadprog", "quantmod", "R.utils", "raster", "rasterVis", "Rcpp", "RcppArmadillo", "reprex", "reproj", "ResourceSelection", "rgdal", "rgeos", "rlang", "rmarkdown", "rpart", "rvest", "SDMTools", "sf", "shiny", "spatstat", "spex", "stars", "survival", "sys", "tibble", "tinytex", "tseries", "units", "usethis", "vctrs", "xfun", "XML", "xml2", "xtable", "zoo"))
install.packages("remotes")
remotes::install_github("mccreigh/rwrfhydro")
remove.packages("Rcpp")
install.packages("Rcpp")
install.packages("remotes")
remotes::install_github("mccreigh/rwrfhydro")
# A slightly different approach using rwrfhydro package
FDCDF <- CalcFdc(hydrograph,strCol="discharge")
library(rwrfhydro)
library("rwrfhydro")
library('rwrfhydro')
# A slightly different approach using rwrfhydro package
FDCDF <- CalcFdc(hydrograph,strCol="discharge")
View(FDCDF)
FDCSP <- CalcFdcSpline(FDCDF,strCol = "discharge")
View(FDCSP)
plot(FDCSP())
View(FDCDF)
write.csv(FDCDF,file="FDCDF_Beasley1")
write.csv(FDCDF,file="FDCDF_Beasley1.csv")
# trying to use a modified version of
plot(x=ln(FDCDF$discharge),y=FDCDF$discharge.fdc)
plot(x=log(FDCDF$discharge),y=FDCDF$discharge.fdc)
# trying to use a modified version of
plot(x=log(FDCDF$discharge.fdc),y=FDCDF$discharge)
plot(x=FDCDF$discharge.fdc,y=log(FDCDF$discharge))
# trying to use a Sasymp
trialSymp <- SSasymp(intTot$EP,0,1000000,-5.11)
# trying to use a Sasymp
intTot$trialSymp <- SSasymp(intTot$EP,0,1000000,-5.11)
View(intTot)
fit <- nls(intTot$discharge~intTot$trialSymp)
dfMQ <- data.frame(discharge=modeled_q)
uniqueQ <- bind_rows(hydroEP,data.frame(anti_join(dfMQ["discharge"],hydroEP["discharge"]))) # all discharges that will be in area-lookup table
uniqueQ <- unique(arrange(uniqueQ,discharge)) # puts discharges in ascending order and removes duplicates
intTot <- data.frame(approx(x=uniqueQ$discharge,y=uniqueQ$EP,method="linear",xout=uniqueQ$discharge)) # linearly interpolate for missing total available area values
names(intTot) <- c("discharge","EP")
# trying to use NLS
trying <- nls(y~b*x^z,start = list(b = 50, z = -1),data=intTot)
